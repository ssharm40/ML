{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f57fbaf",
   "metadata": {},
   "source": [
    "## Topics-\n",
    "\n",
    "1) Ensemble Tech-------- i) Bagging\n",
    "                        ii) Boosting\n",
    "    \n",
    "    \n",
    "2) Random Forest\n",
    "\n",
    "3) Adaboost\n",
    "\n",
    "4) XGboost(extremely gradient boosting)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d885217",
   "metadata": {},
   "source": [
    "#                                                       Ensemble Tech\n",
    "\n",
    "\n",
    "\n",
    "Works on both=> Classification,Regression\n",
    "\n",
    "Here we apply many algorithm at the same time and get the answer\n",
    "\n",
    "\n",
    "We can do the ensemble by 2 ways-\n",
    "\n",
    "1) Bagging\n",
    "2) Boosting\n",
    "\n",
    "\n",
    "\n",
    "## Bagging\n",
    "\n",
    "We create many model model parallerly and these models are dependent from each other\n",
    "\n",
    "So we perform sampling of rows and gives to Model1 then same Model2 and so on\n",
    "\n",
    "So for testing the data we give test data to each model and each model will give you some result.\n",
    "\n",
    "The majority of result will be our answer.\n",
    "\n",
    "In regression we take the mean of all the answers.\n",
    "\n",
    "\n",
    "The majority voting step is known as **Bootstrap Aggregation**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Boosting\n",
    "\n",
    "In boosting we create the model sequentially and all the models are dependent.\n",
    "\n",
    "\n",
    "Data-------------> M1-----> M2----->M3_____________ O/p\n",
    "           Weak learner    ---     ---\n",
    "\n",
    "\n",
    "So each model is known as weak learner here and then we combine the result of all the models then we will get the best learner\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40e6b89",
   "metadata": {},
   "source": [
    "##                                     Random Forest\n",
    "\n",
    "\n",
    "It'based on bagging technique.\n",
    "Here we use decision trees only.\n",
    "\n",
    "\n",
    "First Qus:- What was the probelm in Decision Tree?\n",
    "Decision tree leads to overfitting bcoz it split the nodel for each datapoint\n",
    "\n",
    "Obviously there are some hyperparameter turing(post, pre puring) available in decision tree but still it become typical to overcome from overfitting \n",
    "\n",
    "Overfitting Means=====>       Low  Bias\n",
    "                              High Variance                  \n",
    "\n",
    "\n",
    "\n",
    "But the generalized model should have====> Low Bias\n",
    "                                           Low Variance\n",
    "                                           \n",
    "\n",
    "So bcoz of this we use Random Forest so that we can generalized model.\n",
    "\n",
    "\n",
    "\n",
    "Qus:- Is Normalization requires in Random Forest? -----------> No\n",
    "      Is Normalization requires in KNN? ---------------------> Yes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Qus:- Is outliers affect Random Forest? -----------> No\n",
    "      Is outliers affect KNN?----------------------> Yes\n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "      \n",
    "In Bagging technique most of the time we use Random Funtion only\n",
    "But One more method is available i.e., Custom bagging-------- Means create multiple kind of modelmanually and get the output.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d36b8",
   "metadata": {},
   "source": [
    "##                                  Adaboost\n",
    "\n",
    "Boosting technique\n",
    "Weak Learner Concept\n",
    "Here we also create decision tree only\n",
    "\n",
    "\n",
    "In this model first we assign the mail to each row(1/total no of rows) and it sum should be 1.\n",
    "After assigning the weight we calculate the Information gain to decide which feature should we take first(Suppose you take F1)\n",
    "\n",
    "\n",
    "Then we create a decision tree for that feature<Only 1-depth decision tree> and this tree is also known as stump1\n",
    "\n",
    "So we check the accuracy of each row on this stump then whatever result we get wrong in the next step we will takle more value \n",
    "to that\n",
    "\n",
    "suppose you get 1 error froom 7\n",
    "\n",
    "so your total Error is 1/7\n",
    "\n",
    "Then perform perfomance formula\n",
    "\n",
    "Then update new weight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e3b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ac76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c4520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9446f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a00f52f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c0e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd8a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d3ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62159d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c3715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
